{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254ff8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x122a54910>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d9824",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9218b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Brent data\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Downloading USD/RUB data\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8867, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def open_df(name, date_from, date_to):\n",
    "    return yf.download(name, date_from, date_to, interval='1h').reset_index()\n",
    "\n",
    "print('Downloading Brent data')\n",
    "df_brent = open_df('BZ=F', \"2021-01-01\", \"2022-12-12\")\n",
    "print('Downloading USD/RUB data')\n",
    "df_usd = open_df('RUB=X', \"2021-01-01\", \"2022-12-12\")\n",
    "\n",
    "df = pd.merge(df_usd, df_brent, on='index')\n",
    "df.drop(columns=['Volume_x'], inplace=True)\n",
    "df.set_index('index', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d68b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ac25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_features(df, target_column, size):\n",
    "    df_new = df.sort_index(ascending=True).copy()\n",
    "\n",
    "    columns = df.columns\n",
    "    feature_columns = list(set(columns) - {target_column,})\n",
    "    for column in columns:\n",
    "        for shift in range(1, size + 1):\n",
    "            feature_values = df_new[column].values\n",
    "            feature_values_shifted = np.roll(feature_values, -shift)\n",
    "            df_new[column + '_' + str(shift)] = feature_values_shifted\n",
    "\n",
    "    y = df_new[target_column]\n",
    "\n",
    "    df_new = df_new.drop(columns, axis=1)\n",
    "\n",
    "    res_df = df_new.iloc[:-size]\n",
    "    res_y = pd.Series(np.roll(y.diff(), -1)[:-size], index=res_df.index)\n",
    "    return res_df, res_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07000317",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c8fa728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.588099889393787\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "widow_size = 1\n",
    "X, y = sliding_window_features(df, 'Close_x', widow_size)\n",
    "cb = CatBoostRegressor()\n",
    "cb.fit(X[:train_size], y[:train_size], verbose=False)\n",
    "print(f'RMSE:', np.sqrt(np.mean((y[train_size:] - cb.predict(X[train_size:]))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1530ca93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5912915270204362\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "widow_size = 5\n",
    "X, y = sliding_window_features(df, 'Close_x', widow_size)\n",
    "cb = CatBoostRegressor()\n",
    "cb.fit(X[:train_size], y[:train_size], verbose=False)\n",
    "print(f'RMSE:', np.sqrt(np.mean((y[train_size:] - cb.predict(X[train_size:]))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be05abf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n",
      "/var/folders/lw/v8xx90_s5mj452fmqx1ltbtr0000gn/T/ipykernel_16436/2899716042.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new[column + '_' + str(shift)] = feature_values_shifted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5742990231469814\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "widow_size = 10\n",
    "X, y = sliding_window_features(df, 'Close_x', widow_size)\n",
    "cb = CatBoostRegressor()\n",
    "cb.fit(X[:train_size], y[:train_size], verbose=False)\n",
    "print(f'RMSE:', np.sqrt(np.mean((y[train_size:] - cb.predict(X[train_size:]))**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccaae3a",
   "metadata": {},
   "source": [
    "# RMDN (Recurrent Mixture Density Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656c6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialDataset(Dataset):\n",
    "    def __init__(self, X, y, sequence_length):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32)\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx:idx+self.sequence_length], self.y[idx+self.sequence_length]\n",
    "\n",
    "X, y = sliding_window_features(df, 'Close_x', 1)\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b81186e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "widow_size = 1\n",
    "\n",
    "train_dataset1 = FinancialDataset(X_train, y_train, widow_size)\n",
    "test_dataset1 = FinancialDataset(X_test, y_test, widow_size)\n",
    "\n",
    "train_dataloader1 = DataLoader(train_dataset1, batch_size=16, shuffle=False)\n",
    "test_dataloader1 = DataLoader(test_dataset1, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90066c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "widow_size = 5\n",
    "\n",
    "train_dataset5 = FinancialDataset(X_train, y_train, widow_size)\n",
    "test_dataset5 = FinancialDataset(X_test, y_test, widow_size)\n",
    "\n",
    "train_dataloader5 = DataLoader(train_dataset5, batch_size=16, shuffle=False)\n",
    "test_dataloader5 = DataLoader(test_dataset5, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a71cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "widow_size = 10\n",
    "\n",
    "train_dataset10 = FinancialDataset(X_train, y_train, widow_size)\n",
    "test_dataset10 = FinancialDataset(X_test, y_test, widow_size)\n",
    "\n",
    "train_dataloader10 = DataLoader(train_dataset10, batch_size=16, shuffle=False)\n",
    "test_dataloader10 = DataLoader(test_dataset10, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a23f7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDN(nn.Module):\n",
    "    def __init__(self, in_features, num_distributions):\n",
    "        super(MDN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.num_distributions = num_distributions\n",
    "        \n",
    "        self.pi = nn.Linear(in_features, num_distributions)\n",
    "        self.mu = nn.Linear(in_features, num_distributions)\n",
    "        self.sigma = nn.Linear(in_features, num_distributions)\n",
    "        self.elu = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pi = F.gumbel_softmax(self.pi(x), dim=-1, tau=1)\n",
    "        mu = self.mu(x)\n",
    "        sigma = self.elu(self.sigma(x)) + 1 + 1e-15\n",
    "        return pi, mu, sigma\n",
    "\n",
    "\n",
    "class RMDN(nn.Module):\n",
    "    def __init__(self, in_features=11, hidden_size=32, num_distributions=2):\n",
    "        super(RMDN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_distributions = num_distributions\n",
    "        \n",
    "        self.GRU = nn.GRU(in_features, hidden_size, batch_first=True)\n",
    "        self.MDN = MDN(hidden_size, num_distributions)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.autograd.Variable(torch.zeros(1, x.shape[0], self.hidden_size))\n",
    "        out, h = self.GRU(x, h0)\n",
    "        out = out[:,-1,:]\n",
    "        pi, mu, sigma = self.MDN(out)\n",
    "        return pi, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa0e961b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_rmse(model, test_dataset, test_dataloader):\n",
    "    mse = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch_x, batch_y in tqdm(test_dataloader, desc='Test'):\n",
    "            pi, mu, sigma = model(batch_x)\n",
    "            value = torch.sum(pi * mu, dim=1)  # expected values\n",
    "            err = batch_y - value\n",
    "            mse += torch.sum(err**2)\n",
    "    return torch.sqrt(mse / len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfdf8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONEOVERSQRT2PI = 1.0 / np.sqrt(2 * np.pi)\n",
    "LOG2PI = np.log(2 * np.pi)\n",
    "\n",
    "def log_pdf(sigma, mu, target):\n",
    "    target = target.expand_as(sigma)\n",
    "    return -torch.log(sigma) - 0.5 * LOG2PI - 0.5 * torch.pow((target - mu) / sigma, 2)\n",
    "\n",
    "def log_prob_y(pi, sigma, mu, y):\n",
    "    log_component_prob = log_pdf(sigma, mu, y)\n",
    "    log_mix_prob = torch.log(pi + 1e-15)\n",
    "    return torch.logsumexp(log_component_prob + log_mix_prob, dim=-1)\n",
    "\n",
    "def calculate_loss(y, pi, mu, sigma, model, lambda_pi=1.0):\n",
    "    log_prob = log_prob_y(pi, sigma, mu, y)\n",
    "    loss = torch.mean(-log_prob)\n",
    "    \n",
    "    pi_l1_reg = 0\n",
    "    if lambda_pi > 0:\n",
    "        pi_params = torch.cat([x.view(-1) for x in model.MDN.pi.parameters()])\n",
    "        pi_l1_reg = lambda_pi * torch.norm(pi_params, 1)\n",
    "\n",
    "    loss = loss + pi_l1_reg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52daf3b7",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5718c809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 100%|██████████████████████████████| 438/438 [00:00<00:00, 715.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 2.296644694865022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 3427.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5971273183822632\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 100%|██████████████████████████████| 438/438 [00:00<00:00, 749.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.8069088954104272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 3430.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5923519134521484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 100%|██████████████████████████████| 438/438 [00:00<00:00, 749.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.5725885226421025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 3412.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5896502137184143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 100%|██████████████████████████████| 438/438 [00:00<00:00, 765.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.42528837803085695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 3360.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5925706028938293\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 100%|██████████████████████████████| 438/438 [00:00<00:00, 767.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.34557035468841935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 3025.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5872411727905273\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 100%|██████████████████████████████| 438/438 [00:00<00:00, 748.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.33067598465360176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 3117.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5875681042671204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 100%|██████████████████████████████| 438/438 [00:00<00:00, 769.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.3292898225340754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 3244.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5870961546897888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 100%|██████████████████████████████| 438/438 [00:00<00:00, 768.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.2923473850643203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 3037.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5853250026702881\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 100%|██████████████████████████████| 438/438 [00:00<00:00, 761.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.2686071776504284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 3266.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5861722230911255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 100%|█████████████████████████████| 438/438 [00:00<00:00, 766.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.26257005769341596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 3214.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5845715403556824\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_distributions = 3\n",
    "hidden_size = 4\n",
    "lambda_pi = 1\n",
    "EPOCHS = 10\n",
    "\n",
    "model1 = RMDN(num_distributions=num_distributions, hidden_size=hidden_size)\n",
    "opt = torch.optim.Adam(model1.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    for batch_x, batch_y in tqdm(train_dataloader1, desc=f'Epoch #{epoch + 1}'):\n",
    "        pi, mu, sigma = model1(batch_x)\n",
    "        opt.zero_grad()\n",
    "        loss = calculate_loss(torch.unsqueeze(batch_y, 1), pi, mu, sigma, model1, lambda_pi)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print('Mean loss:', np.mean(losses))\n",
    "    print('RMSE:', test_rmse(model1, test_dataset1, test_dataloader1).item())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5ccdf7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 100%|██████████████████████████████| 438/438 [00:00<00:00, 552.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 3.6001541000114727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 2626.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5778466463088989\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 100%|██████████████████████████████| 438/438 [00:00<00:00, 538.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.928514900170777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 2682.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5751797556877136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 100%|██████████████████████████████| 438/438 [00:00<00:00, 539.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.599725710272738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 2591.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.575258731842041\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 100%|██████████████████████████████| 438/438 [00:00<00:00, 546.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.450636208088235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 2566.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.575262725353241\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 100%|██████████████████████████████| 438/438 [00:00<00:00, 558.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.35003975385026026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 2730.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5757960081100464\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 100%|██████████████████████████████| 438/438 [00:00<00:00, 552.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.32964971010279775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 2459.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5752806663513184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 100%|██████████████████████████████| 438/438 [00:00<00:00, 562.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.3079636396197538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 2344.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5756882429122925\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 100%|██████████████████████████████| 438/438 [00:00<00:00, 557.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.2878580707094534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 2312.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5758106708526611\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 100%|██████████████████████████████| 438/438 [00:00<00:00, 559.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.26278335006575876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 2290.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5760579109191895\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 100%|█████████████████████████████| 438/438 [00:00<00:00, 559.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.23585541160951567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 117/117 [00:00<00:00, 2699.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5749793648719788\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_distributions = 3\n",
    "hidden_size = 4\n",
    "lambda_pi = 1\n",
    "EPOCHS = 10\n",
    "\n",
    "model5 = RMDN(num_distributions=num_distributions, hidden_size=hidden_size)\n",
    "opt = torch.optim.Adam(model5.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    for batch_x, batch_y in tqdm(train_dataloader5, desc=f'Epoch #{epoch + 1}'):\n",
    "        pi, mu, sigma = model5(batch_x)\n",
    "        opt.zero_grad()\n",
    "        loss = calculate_loss(torch.unsqueeze(batch_y, 1), pi, mu, sigma, model5, lambda_pi)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print('Mean loss:', np.mean(losses))\n",
    "    print('RMSE:', test_rmse(model5, test_dataset5, test_dataloader5).item())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18e4d3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 100%|██████████████████████████████| 437/437 [00:01<00:00, 408.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 3.6531226758416784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 116/116 [00:00<00:00, 2160.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.584004819393158\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 100%|██████████████████████████████| 437/437 [00:01<00:00, 414.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 1.0951985549373506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 116/116 [00:00<00:00, 2310.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5801214575767517\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 100%|██████████████████████████████| 437/437 [00:01<00:00, 407.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.6562793080948583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 116/116 [00:00<00:00, 2023.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5899003148078918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 100%|██████████████████████████████| 437/437 [00:01<00:00, 418.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.4894120993403807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 116/116 [00:00<00:00, 2264.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5808768272399902\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 100%|██████████████████████████████| 437/437 [00:01<00:00, 418.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.3888614271043904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 116/116 [00:00<00:00, 2271.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5824952125549316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 100%|██████████████████████████████| 437/437 [00:01<00:00, 417.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.3316093989790713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 116/116 [00:00<00:00, 2248.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5766773819923401\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 100%|██████████████████████████████| 437/437 [00:01<00:00, 427.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.2671444365473409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 116/116 [00:00<00:00, 2250.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5790630578994751\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 100%|██████████████████████████████| 437/437 [00:01<00:00, 425.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.265531087352029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 116/116 [00:00<00:00, 2201.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5771614909172058\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 100%|██████████████████████████████| 437/437 [00:01<00:00, 358.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.2605245318833858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 116/116 [00:00<00:00, 1634.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.576400876045227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 100%|█████████████████████████████| 437/437 [00:01<00:00, 362.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.2468990767768902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|█████████████████████████████████| 116/116 [00:00<00:00, 2119.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5767474174499512\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_distributions = 3\n",
    "hidden_size = 4\n",
    "lambda_pi = 1\n",
    "EPOCHS = 10\n",
    "\n",
    "model10 = RMDN(num_distributions=num_distributions, hidden_size=hidden_size)\n",
    "opt = torch.optim.Adam(model10.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    for batch_x, batch_y in tqdm(train_dataloader10, desc=f'Epoch #{epoch + 1}'):\n",
    "        pi, mu, sigma = model10(batch_x)\n",
    "        opt.zero_grad()\n",
    "        loss = calculate_loss(torch.unsqueeze(batch_y, 1), pi, mu, sigma, model10, lambda_pi)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print('Mean loss:', np.mean(losses))\n",
    "    print('RMSE:', test_rmse(model10, test_dataset10, test_dataloader10).item())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2ccc6",
   "metadata": {},
   "source": [
    "Применение для определение цены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "314bd9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1883.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5268271565437317, 0.054691689008042894)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THR = 1.5\n",
    "\n",
    "mse = 0\n",
    "num = 0\n",
    "with torch.inference_mode():\n",
    "    for batch_x, batch_y in tqdm(test_dataloader1):\n",
    "        pi, mu, sigma = model1(batch_x)\n",
    "        value = torch.sum(pi * mu, dim=1)  # expected values\n",
    "        recomended = torch.exp(log_prob_y(pi, sigma, mu, torch.unsqueeze(value, 1))) > THR\n",
    "        err = (batch_y - value)[recomended]\n",
    "        mse += torch.sum(err**2)\n",
    "        num += recomended.sum()\n",
    "torch.sqrt(mse / num).item(), num.item() / len(test_dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "901ebbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 117/117 [00:00<00:00, 1632.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5685878396034241, 0.25040300913487373)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THR = 3\n",
    "\n",
    "mse = 0\n",
    "num = 0\n",
    "with torch.inference_mode():\n",
    "    for batch_x, batch_y in tqdm(test_dataloader5):\n",
    "        pi, mu, sigma = model5(batch_x)\n",
    "        value = torch.sum(pi * mu, dim=1)  # expected values\n",
    "        recomended = torch.exp(log_prob_y(pi, sigma, mu, torch.unsqueeze(value, 1))) > THR\n",
    "        err = (batch_y - value)[recomended]\n",
    "        mse += torch.sum(err**2)\n",
    "        num += recomended.sum()\n",
    "torch.sqrt(mse / num).item(), num.item() / len(test_dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64714345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 116/116 [00:00<00:00, 1395.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5197395086288452, 0.11961206896551724)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THR = 3\n",
    "\n",
    "mse = 0\n",
    "num = 0\n",
    "with torch.inference_mode():\n",
    "    for batch_x, batch_y in tqdm(test_dataloader10):\n",
    "        pi, mu, sigma = model10(batch_x)\n",
    "        value = torch.sum(pi * mu, dim=1)  # expected values\n",
    "        recomended = torch.exp(log_prob_y(pi, sigma, mu, torch.unsqueeze(value, 1))) > THR\n",
    "        err = (batch_y - value)[recomended]\n",
    "        mse += torch.sum(err**2)\n",
    "        num += recomended.sum()\n",
    "torch.sqrt(mse / num).item(), num.item() / len(test_dataset10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
